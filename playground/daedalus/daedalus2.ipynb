{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9owAi2LSQ53-"
      },
      "outputs": [],
      "source": [
        "# update gdown, used to download stuff from google drive\n",
        "!pip install -q --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBdT44axylCA"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "!gdown -q -O dataset.zip 1Mrx0OKnBFteOw1q8IZy-n8x9q8cxZwhT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fPEx1_xys7w"
      },
      "outputs": [],
      "source": [
        "# unzip dataset\n",
        "!unzip -q -o dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fH2dc36xtGg",
        "outputId": "44f2432a-884e-418f-87bf-739a416349af"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import tensorflow as tf\n",
        "\n",
        "from loguru import logger\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "DAEDALUS2_DIR = pathlib.Path(\"/workspaces/playground/playground/daedalus\")\n",
        "\n",
        "TRAIN_DATASET_DIR = DAEDALUS2_DIR / \"post-processed\"\n",
        "TRAIN_DATASET_IMAGE_SIZE = (112, 112)\n",
        "TRAIN_DATASET_CLASS_COUNT = 2996\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "\n",
        "DATABASE_DIR = DAEDALUS2_DIR / \"features_database\"\n",
        "MODEL_WEIGHTS_PATH = DAEDALUS2_DIR / \"feature_extractor\" / \"weights\"\n",
        "FEATURE_VECTOR_SIZE = 128\n",
        "\n",
        "MARQUINHO_TRAIN_IMAGE_PATH = DAEDALUS2_DIR / \"marquinho_train.jpg\"\n",
        "MARQUINHO_TEST_IMAGE_PATH = DAEDALUS2_DIR / \"marquinho_test.jpg\"\n",
        "\n",
        "RNG_SEED = 42\n",
        "\n",
        "# ensure directories exist\n",
        "assert TRAIN_DATASET_DIR.exists()\n",
        "MODEL_WEIGHTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_if_images_have_same_shape(\n",
        "    dataset_dir: pathlib.Path = TRAIN_DATASET_DIR,\n",
        ") -> None:\n",
        "    paths = dataset_dir.rglob(\"*.jpg\")\n",
        "    imgs = [cv2.imread(str(p)) for p in paths]\n",
        "    shapes = [img.shape for img in imgs]\n",
        "    return np.all(np.asarray(shapes)), shapes[0]\n",
        "\n",
        "\n",
        "# check_if_images_have_same_shape()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "909BnN-3yZmo",
        "outputId": "6a8342f5-5e9b-4afb-f6cb-71a6d623de36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12000 files belonging to 2996 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-09 19:45:32.617287: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 19:45:33.019329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46712 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(256, 112, 112, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(256, 2996), dtype=tf.float32, name=None))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_dataset(\n",
        "    dataset_dir: pathlib.Path = TRAIN_DATASET_DIR,\n",
        "    rng_seed: int = RNG_SEED,\n",
        "    batch_size: int = TRAIN_BATCH_SIZE,\n",
        ") -> tf.data.Dataset:\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=dataset_dir,\n",
        "        batch_size=None,\n",
        "        image_size=TRAIN_DATASET_IMAGE_SIZE,\n",
        "        label_mode=\"categorical\",\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        ds.map(lambda d, t: (tf.keras.applications.resnet_v2.preprocess_input(d), t))\n",
        "        .cache()\n",
        "        .shuffle(\n",
        "            buffer_size=ds.cardinality().numpy(),\n",
        "            seed=rng_seed,\n",
        "            reshuffle_each_iteration=True,\n",
        "        )\n",
        "        .batch(batch_size, drop_remainder=True)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "\n",
        "load_dataset().element_spec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tLZfcdhdOrLg"
      },
      "outputs": [],
      "source": [
        "def create_models() -> tf.keras.Model:\n",
        "    base = tf.keras.applications.ResNet50V2(\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=TRAIN_DATASET_IMAGE_SIZE + (3,),\n",
        "        include_top=False,\n",
        "    )\n",
        "\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    augmented_input = tf.keras.Input(shape=TRAIN_DATASET_IMAGE_SIZE + (3,))\n",
        "\n",
        "    data_aug = tf.keras.layers.RandomFlip(mode=\"horizontal\")(augmented_input)\n",
        "    data_aug = tf.keras.layers.RandomRotation(factor=15.0 / 360)(data_aug)\n",
        "    data_aug = tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1)(data_aug)\n",
        "\n",
        "    base_model_out = base(data_aug)\n",
        "\n",
        "    # the arch is not particularly important\n",
        "    flatten = tf.keras.layers.Flatten()(base_model_out)\n",
        "    dense1 = tf.keras.layers.Dense(512, activation=\"relu\")(flatten)\n",
        "    dense1 = tf.keras.layers.BatchNormalization()(dense1)\n",
        "    dense2 = tf.keras.layers.Dense(256, activation=\"relu\")(dense1)\n",
        "    dense2 = tf.keras.layers.BatchNormalization()(dense2)\n",
        "\n",
        "    # we want the values to be between 0, 1\n",
        "    extractor_output = tf.keras.layers.Dense(FEATURE_VECTOR_SIZE, activation=\"sigmoid\")(dense2)\n",
        "\n",
        "    feature_extractor = tf.keras.Model(\n",
        "        inputs=augmented_input,\n",
        "        outputs=extractor_output,\n",
        "        name=\"feature_extractor\",\n",
        "    )\n",
        "\n",
        "    softmax = tf.keras.layers.Dense(TRAIN_DATASET_CLASS_COUNT, \"softmax\")(extractor_output)\n",
        "    classifier = tf.keras.Model(\n",
        "        inputs=augmented_input,\n",
        "        outputs=softmax,\n",
        "        name=\"classifier\",\n",
        "    )\n",
        "\n",
        "    classifier.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=\"accuracy\",\n",
        "    )\n",
        "\n",
        "    return feature_extractor, classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkIccjZjkaxA",
        "outputId": "09cfb1c4-55a4-48aa-b858-d52996db5f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f223c78ece0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_or_create_feature_extractor(\n",
        "    train_dataset_dir: pathlib.Path = TRAIN_DATASET_DIR,\n",
        "    model_weights_path: pathlib.Path = MODEL_WEIGHTS_PATH,\n",
        ") -> tf.keras.Model:\n",
        "    feature_extractor, classifier = create_models()\n",
        "\n",
        "    try:\n",
        "        classifier.load_weights(model_weights_path).expect_partial()\n",
        "    except tf.errors.NotFoundError:\n",
        "        ds = load_dataset(dataset_dir=train_dataset_dir)\n",
        "        classifier.fit(ds, epochs=999, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5)])\n",
        "        classifier.save_weights(model_weights_path, save_format=\"tf\")\n",
        "\n",
        "    return feature_extractor\n",
        "\n",
        "load_or_create_feature_extractor()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature extraction, assumes the model was trained already"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features_vector(\n",
        "    image: npt.NDArray[np.float32],\n",
        "    feature_extractor: tf.keras.Model,\n",
        ") -> npt.NDArray[np.float32]:\n",
        "    \n",
        "    if image.shape == TRAIN_DATASET_IMAGE_SIZE + (3,):\n",
        "        fixed_size = image\n",
        "    else:\n",
        "        fixed_size = cv2.resize(image, TRAIN_DATASET_IMAGE_SIZE)\n",
        "    \n",
        "    preprocessed = tf.keras.applications.resnet_v2.preprocess_input(fixed_size)\n",
        "    batched = preprocessed.reshape(1, *preprocessed.shape)\n",
        "    return feature_extractor.predict(batched).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_new_instance_to_database(\n",
        "    image: npt.NDArray[np.float32],\n",
        "    instance_label: str,\n",
        "    instance_id: str,\n",
        "    database_dir: pathlib.Path,\n",
        "    feature_extractor: tf.keras.Model,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    `instance_path`: path to the image to be added to the database\n",
        "    `instance_label`: the name or identifier of the the instance\n",
        "    `database_dir`: location of the database\n",
        "    `feature_extractor`: a pre-trained neural network that generated feature vectors\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(f\"storing new instance, label={instance_label}, instance_id={instance_id}\")\n",
        "\n",
        "    feature_vector = extract_features_vector(\n",
        "        image=image,\n",
        "        feature_extractor=feature_extractor,\n",
        "    )\n",
        "\n",
        "    # create, if necessary, the label dir\n",
        "    label_dir = database_dir / instance_label\n",
        "    label_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    features_vector_path =(label_dir / instance_id).with_suffix(\".npy\")\n",
        "    if features_vector_path.exists():\n",
        "        logger.warning(\n",
        "            \"there is already an instance with this instance_id in the database, overwriting\"\n",
        "        )\n",
        "\n",
        "    np.save(\n",
        "        file=features_vector_path,\n",
        "        arr=feature_vector,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def populate_database_with_train_dataset(\n",
        "    feature_extractor: tf.keras.Model,\n",
        "    train_dataset_dir: pathlib.Path = TRAIN_DATASET_DIR,\n",
        "    database_dir: pathlib.Path = DATABASE_DIR,\n",
        ") -> None:\n",
        "    for label_dir in train_dataset_dir.iterdir():\n",
        "        for image_path in label_dir.iterdir():\n",
        "            add_new_instance_to_database(\n",
        "                image=cv2.imread(str(image_path)),\n",
        "                instance_label=label_dir.name,\n",
        "                instance_id=image_path.stem,\n",
        "                database_dir=database_dir,\n",
        "                feature_extractor=feature_extractor\n",
        "            )\n",
        "\n",
        "populate_database_with_train_dataset(\n",
        "    feature_extractor=load_or_create_feature_extractor()\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adding new instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_new_instance_to_database_with_augmentations(\n",
        "    image_path: pathlib.Path,\n",
        "    label: str,\n",
        "    feature_extractor: tf.keras.Model,\n",
        "    database_dir: pathlib.Path = DATABASE_DIR,\n",
        ") -> None:\n",
        "    original_image = cv2.imread(str(image_path))\n",
        "    add_new_instance_to_database(\n",
        "            image=original_image,\n",
        "            instance_label=label,\n",
        "            instance_id=image_path.stem,\n",
        "            database_dir=database_dir,\n",
        "            feature_extractor=feature_extractor,\n",
        "        )\n",
        "\n",
        "    algumentatinator = A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate(limit=15),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    for i in range(16):\n",
        "        augmented = algumentatinator(image=original_image)\n",
        "        add_new_instance_to_database(\n",
        "                image=augmented[\"image\"],\n",
        "                instance_label=label,\n",
        "                instance_id=f\"{image_path.stem}_aug{i}\",\n",
        "                database_dir=database_dir,\n",
        "                feature_extractor=feature_extractor\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_label_encoder(database_dir: pathlib.Path = DATABASE_DIR) -> LabelEncoder:\n",
        "    label_dirs = sorted(database_dir.iterdir())\n",
        "    label_names = [path.name for path in label_dirs]\n",
        "    return LabelEncoder().fit(label_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_feature_vectors_and_labels(\n",
        "    database_dir: pathlib.Path = DATABASE_DIR,\n",
        ") -> tuple[npt.NDArray[np.float32], npt.NDArray[np.int64]]:\n",
        "    paths = list(database_dir.rglob(\"*.npy\"))\n",
        "\n",
        "    features = np.array([np.load(p) for p in paths])\n",
        "\n",
        "    label_encoder = create_label_encoder(database_dir)\n",
        "    labels = [p.parent.name for p in paths]\n",
        "    encoded_labels = label_encoder.transform(labels)\n",
        "    \n",
        "    return features, encoded_labels\n",
        "\n",
        "def _check_load_feature_vectors_and_labels() -> None:\n",
        "    features, labels = load_feature_vectors_and_labels()\n",
        "    print(features.shape, features.dtype)\n",
        "    print(labels.shape, labels.dtype)\n",
        "\n",
        "# _check_load_feature_vectors_and_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_instance(\n",
        "    instance_path: pathlib.Path,\n",
        "    feature_extractor: tf.keras.Model,\n",
        ") -> int:\n",
        "    database_features, database_labels = load_feature_vectors_and_labels()\n",
        "    model = KNeighborsClassifier(weights=\"distance\").fit(database_features, database_labels)\n",
        "\n",
        "    img = cv2.imread(str(instance_path))\n",
        "    resized_img = cv2.resize(img, TRAIN_DATASET_IMAGE_SIZE)\n",
        "    preprocessed = tf.keras.applications.resnet_v2.preprocess_input(resized_img)\n",
        "    batched_image = preprocessed.reshape(1, *preprocessed.shape)\n",
        "    instance_features = feature_extractor.predict(batched_image).flatten()\n",
        "\n",
        "    return model.predict([instance_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: gdown: command not found\n",
            "/bin/bash: gdown: command not found\n"
          ]
        }
      ],
      "source": [
        "!gdown -q -O marquinho_train.jpg \"1EgvzTNEWTXvegURlmJAt8OXOtrKAlQEb\"\n",
        "!gdown -q -O marquinho_test.jpg \"1RcLasSJj-XMke5Fj33adiaHWbbl-9ihW\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show marqinho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-09 19:50:43.712 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train\n",
            "2023-03-09 19:50:44.363 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.366 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug0\n",
            "2023-03-09 19:50:44.417 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.419 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug1\n",
            "2023-03-09 19:50:44.468 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.470 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug2\n",
            "2023-03-09 19:50:44.535 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.537 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug3\n",
            "2023-03-09 19:50:44.600 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.601 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug4\n",
            "2023-03-09 19:50:44.655 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.658 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug5\n",
            "2023-03-09 19:50:44.723 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.725 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug6\n",
            "2023-03-09 19:50:44.776 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.780 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug7\n",
            "2023-03-09 19:50:44.830 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.832 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug8\n",
            "2023-03-09 19:50:44.878 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.879 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug9\n",
            "2023-03-09 19:50:44.935 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.938 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug10\n",
            "2023-03-09 19:50:44.990 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:44.995 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug11\n",
            "2023-03-09 19:50:45.054 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:45.059 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug12\n",
            "2023-03-09 19:50:45.114 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:45.117 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug13\n",
            "2023-03-09 19:50:45.173 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:45.176 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug14\n",
            "2023-03-09 19:50:45.226 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n",
            "2023-03-09 19:50:45.227 | INFO     | __main__:add_new_instance_to_database:15 - storing new instance, label=marquinho, instance_id=marquinho_train_aug15\n",
            "2023-03-09 19:50:45.281 | WARNING  | __main__:add_new_instance_to_database:28 - there is already an instance with this instance_id in the database, overwriting\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2996] [2996]\n"
          ]
        }
      ],
      "source": [
        "add_new_instance_to_database_with_augmentations(\n",
        "    image_path=MARQUINHO_TRAIN_IMAGE_PATH,\n",
        "    label=\"marquinho\",\n",
        "    feature_extractor=load_or_create_feature_extractor(),\n",
        "    database_dir=DATABASE_DIR,\n",
        ")\n",
        "\n",
        "expeced_label = create_label_encoder().transform([\"marquinho\"])\n",
        "predicted_label = classify_instance(MARQUINHO_TEST_IMAGE_PATH, load_or_create_feature_extractor())\n",
        "\n",
        "print(expeced_label, predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
